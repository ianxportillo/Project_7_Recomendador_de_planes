{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recomendador de planes\n",
    "\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. Quieren desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga de datos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar todas las librerías\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #Librería para poder dividir los dataframes\n",
    "from sklearn.tree import DecisionTreeClassifier #Librería para el modelado por árbol de decisión\n",
    "from sklearn.ensemble import RandomForestClassifier #Librería para el modelado por bosque aleatorio\n",
    "from sklearn.linear_model import LogisticRegression #Librería para el modelado por regresión logística\n",
    "from sklearn.metrics import accuracy_score #Librería para el calculo de la exactitud de los modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de los datos\n",
    "\n",
    "- сalls — número de llamadas\n",
    "- minutes — duración total de la llamada en minutos\n",
    "- messages — número de mensajes de texto\n",
    "- mb_used — Tráfico de Internet utilizado en MB\n",
    "- is_ultra — plan para el mes actual (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Carga los archivos de datos \n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que el dataset no presenta duplicados ni valores ausentes, por lo tanto, no se realizarán mayores modificaciones en el dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train.drop('is_ultra', axis=1)\n",
    "target = train['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividiremos los datos en 3 secciones: entrenamiento, validación y prueba. Se dividirán los siguientes porcentajes:\n",
    "\n",
    "- 60% entrenamiento\n",
    "- 20% validación\n",
    "- 20% prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train_val, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procentaje del dataframe de entrenamiento: 59.98755444928439\n",
      "Porcentaje del dataframe de validación: 20.00622277535781\n",
      "Porcentaje del dataframe de prueba: 20.00622277535781\n"
     ]
    }
   ],
   "source": [
    "print('Procentaje del dataframe de entrenamiento:',train.shape[0]/df.shape[0]*100)\n",
    "print('Porcentaje del dataframe de validación:',val.shape[0]/df.shape[0]*100)\n",
    "print('Porcentaje del dataframe de prueba:',test.shape[0]/df.shape[0]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los dataframes contienen la cantidad de filas adecuadas conforme a los porcentajes establecidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las secciones features y target para cada dataframe. Para features usaremos todos las columnas menos is_ultra y para target usaremos is_ultra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.drop('is_ultra', axis=1)\n",
    "train_target = train['is_ultra']\n",
    "val_features = val.drop('is_ultra', axis=1)\n",
    "val_target = val['is_ultra']\n",
    "test_features = test.drop('is_ultra', axis=1)\n",
    "test_target = test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelado de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección calcularemos y compararemos la exactitud de 3 módelos (árbol de decisión, bosque aleatorio y regresión logística) para determinar el que tenga una exactitud más cercana, igual o superior al objetivo que tenemos que es de 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud Training set: 1.0\n",
      "Exactitud Test set: 0.7340590979782271\n",
      "Exactitud Validation set: 0.7231726283048211\n"
     ]
    }
   ],
   "source": [
    "#Entrenamos el modelo con los datos de entrenamiento y calculamos la exactitud\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features, target)\n",
    "train_predictions = model.predict(features)\n",
    "print('Exactitud Training set:', accuracy_score(target, train_predictions))\n",
    "\n",
    "test_predictions = model.predict(test_features)\n",
    "print('Exactitud Test set:', accuracy_score(test_target, test_predictions))\n",
    "\n",
    "val_predictions = model.predict(val_features)\n",
    "print('Exactitud Validation set:', accuracy_score(val_target, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin ajustar los hiperparámetros, observamos que el modelo no cuenta con la exactitud requerida, así que procederemos a ajustar para verificar si podemos aumentar la exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7418351477449455\n",
      "max_depth = 2 : 0.7744945567651633\n",
      "max_depth = 3 : 0.7744945567651633\n",
      "max_depth = 4 : 0.7807153965785381\n",
      "max_depth = 5 : 0.7713841368584758\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(train_features, train_target)\n",
    "    predictions_valid = model.predict(val_features)\n",
    "    print('max_depth =', depth, ': ', end='')\n",
    "    print(accuracy_score(val_target, predictions_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7698289269051322\n",
      "max_depth = 2 : 0.7900466562986003\n",
      "max_depth = 3 : 0.7776049766718507\n",
      "max_depth = 4 : 0.7900466562986003\n",
      "max_depth = 5 : 0.8040435458786936\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1, 6):\n",
    "    model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    model.fit(train_features, train_target)\n",
    "    predictions_test = model.predict(test_features)\n",
    "    print('max_depth =', depth, ': ', end='')\n",
    "    print(accuracy_score(test_target, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ajustar la profundidad máxima observamos que al utilizar una profundidad de 4 el modelo alcanza una exactitud de 0.781 para el conjunto de validación y 0.790 para el conjunto de prueba, la cual es superior a la esperada, pero seguiremos probando otros modelos para verificar si logramos conseguir una exactitud mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosque aleatorio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de bosque aleatorio variaremos el número de árboles para encontrar el modelo con mayor exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validación (n_estimators = 8): 0.7900466562986003\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 11): # selecciona el rango del hiperparámetro\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est) # configura el número de árboles\n",
    "    model.fit(train_features, train_target) # entrena el modelo en el conjunto de entrenamiento\n",
    "    score = model.score(val_features, val_target) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "    if score > best_score:\n",
    "        best_score = score # guarda la mejor puntuación de accuracy en el conjunto de validación\n",
    "        best_est = est # guarda el número de estimadores que corresponden a la mejor puntuación de accuracy\n",
    "\n",
    "print(\"Exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validación (n_estimators = 8): 0.7978227060653188\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "for est in range(1, 11): # selecciona el rango del hiperparámetro\n",
    "    model = RandomForestClassifier(random_state=54321, n_estimators=est) # configura el número de árboles\n",
    "    model.fit(train_features, train_target) # entrena el modelo en el conjunto de entrenamiento\n",
    "    score = model.score(test_features, test_target) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "    if score > best_score:\n",
    "        best_score = score # guarda la mejor puntuación de accuracy en el conjunto de validación\n",
    "        best_est = est # guarda el número de estimadores que corresponden a la mejor puntuación de accuracy\n",
    "\n",
    "print(\"Exactitud del mejor modelo en el conjunto de validación (n_estimators = {}): {}\".format(best_est, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ajustar el número de árboles observamos que al utilizar un valor de 8 el modelo alcanza una exactitud de 0.790 para el conjunto de validación y 0.798 para el conjunto de prueba, la cual es superior a la esperada, pero seguiremos probando otros modelos para verificar si logramos conseguir una exactitud mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de regresión logística en el conjunto de entrenamiento: 0.703838174273859\n",
      "Exactitud del modelo de regresión logística en el conjunto de validación: 0.7216174183514774\n",
      "Exactitud del modelo de regresión logística en el conjunto de prueba: 0.702954898911353\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=54321, solver='liblinear')  # inicializa el constructor de regresión logística con los parámetros random_state=54321 y solver='liblinear'\n",
    "model.fit(train_features, train_target) # entrena el modelo en el conjunto de entrenamiento\n",
    "score_train = model.score(train_features, train_target) # calcula la puntuación de accuracy en el conjunto de entrenamiento\n",
    "score_val = model.score(val_features, val_target) # calcula la puntuación de accuracy en el conjunto de validación\n",
    "score_test = model.score(test_features, test_target) # calcula la puntuación de accuracy en el conjunto de prueba\n",
    "\n",
    "print(\"Exactitud del modelo de regresión logística en el conjunto de entrenamiento:\", score_train)\n",
    "print(\"Exactitud del modelo de regresión logística en el conjunto de validación:\", score_val)\n",
    "print(\"Exactitud del modelo de regresión logística en el conjunto de prueba:\", score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este dataset, el modelo de regresión logística parecer no ser el más adecuado ya que para el conjunto de validación se obtuvo una exactitud de 0.721 y para el conjunto de prueba fue de 0.703, lo cual, es inferior a lo obtenido por los otros modelos e incluso inferior al valor esperado de exactitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de realizar varias pruebas con los diferentes modelos y ajustar los hiperparámetros se observa que los modelos que mejores resultados arrojaron fue árbol de decisión y bosque aleatorio, ambos teniendo una exactitud superior a la esperada.\n",
    "\n",
    "Cualquiera de estos 2 modelos podrían ser utilizados para seleccionar el mejor plan a recomendar para los usuarios con planes heredados. Si quisiéramos elegir el que mayor exactitud presentó deberíamos seleccionar el modelo bosque aleatorio con una cantidad de árboles igual a 8, pero quisiera concluir el proyecto dando un poco más de información respecto al mejor modelo.\n",
    "\n",
    "Ya que si priorizamos la velocidad del modelo, podríamos sacrificar un poco la exactitud y seleccionar el modelo de árbol de decisión y tener un excelente desempeño, personalmente sería la opción que elegiría, pero como se mencionó en el párrafo anterior, si queremos la mayor exactitud, que podría reflejar mayores ganancias, el modelo bosque aleatorio debería ser elegido."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
